

<!DOCTYPE html>


<html lang="en" data-content_root="../../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Analyzing privacy risk score for classification models &#8212; holistic  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/nbsphinx-code-cells.css?v=2aa19091" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/css/custom_style.css?v=ac75cb35" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../../../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../../_static/copybutton.js?v=f281be69"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'gallery/tutorials/security/measuring_privacy_tutorials/analyzing_privacy_risk_classification';</script>
    <link rel="icon" href="../../../../_static/holistic_ai.png"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../../_static/hai_logo.svg" class="logo__image only-light" alt="holistic  documentation - Home"/>
    <img src="https://assets-global.website-files.com/6305e5d42c283515c3e71b8c/63d771efd50a073bd66193f0_Holistic-AI-Logo-Horizontal-Dark.svg" class="logo__image only-dark pst-js-only" alt="holistic  documentation - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../getting_started/index.html">
    Getting Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../reference/index.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../index.html">
    Example Gallery
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../contributor/index.html">
    Contributor Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../changelog/index.html">
    Changelog
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://twitter.com/holistic_ai" title="Twitter" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Twitter</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/holistic-ai/holisticai" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://join.slack.com/t/holisticaicommunity/shared_invite/zt-2jamouyrn-BrMfeoBZIHT8HbLzB3P9QQ" title="Community" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-slack fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Community</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../getting_started/index.html">
    Getting Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../reference/index.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../index.html">
    Example Gallery
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../contributor/index.html">
    Contributor Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../../../changelog/index.html">
    Changelog
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://twitter.com/holistic_ai" title="Twitter" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Twitter</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/holistic-ai/holisticai" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://join.slack.com/t/holisticaicommunity/shared_invite/zt-2jamouyrn-BrMfeoBZIHT8HbLzB3P9QQ" title="Community" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-slack fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Community</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Analyzing privacy risk score for classification models</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="Analyzing-privacy-risk-score-for-classification-models">
<h1>Analyzing privacy risk score for classification models<a class="headerlink" href="#Analyzing-privacy-risk-score-for-classification-models" title="Link to this heading">#</a></h1>
<p>In this notebook, we will analyze the privacy risks of a classification model. We will use the <a class="reference external" href="https://archive.ics.uci.edu/ml/datasets/Bank+Marketing">bank marketing dataset</a> from the UCI Machine Learning Repository. This dataset is related to direct marketing campaigns of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit.</p>
<p>This is useful for understanding some privacy concepts related to membership inference attacks in machine learning models. To do this, we will use the shadow training technique commonly used in membership inference attacks and then we will evaluate the privacy risk score of a target model concerning the dataset. Then, we will analyze the privacy risk score by changing the model architecture to observe the impact of the model choice on the privacy risk score.</p>
<p>Let’s start by importing the necessary libraries and loading the dataset.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">holistic.datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>

<span class="kn">from</span> <span class="nn">holistic.security.metrics</span> <span class="kn">import</span> <span class="n">privacy_risk_score</span>
</pre></div>
</div>
</div>
<p>To understand the privacy risk score, we will use the shadow training technique. This technique consists of training a shadow model to mimic the target model.</p>
<p>For our purposes, we will assume that the adversary has access to part of the training dataset and full access to the testing dataset. The adversary will use this dataset to train the shadow model, which is a model that tries to mimic the target model.</p>
<p>To do this, once we have our training and testing sets, we will split the training dataset into two parts: the target dataset, which will be used to calculate the probabilities from the target model; and the shadow dataset, which will be used to train the target model. We will use the following proportions: 60% for the target dataset and 40% for the shadow dataset.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s1">&#39;bank_marketing&#39;</span><span class="p">,</span> <span class="n">protected_attribute</span><span class="o">=</span><span class="s1">&#39;marital&#39;</span><span class="p">,</span> <span class="n">preprocessed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_test</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">train_test</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span>
<span class="n">target_shadow</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_target_train</span> <span class="o">=</span> <span class="n">target_shadow</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="s1">&#39;X&#39;</span><span class="p">]</span>
<span class="n">y_target_train</span> <span class="o">=</span> <span class="n">target_shadow</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">][</span><span class="s1">&#39;y&#39;</span><span class="p">]</span>
<span class="n">X_shadow_train</span> <span class="o">=</span> <span class="n">target_shadow</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">][</span><span class="s1">&#39;X&#39;</span><span class="p">]</span>
<span class="n">y_shadow_train</span> <span class="o">=</span> <span class="n">target_shadow</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">][</span><span class="s1">&#39;y&#39;</span><span class="p">]</span>

<span class="n">X_test</span> <span class="o">=</span> <span class="n">train_test</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">][</span><span class="s1">&#39;X&#39;</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">][</span><span class="s1">&#39;y&#39;</span><span class="p">]</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set size:&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set size:&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Target Model Training set size:&quot;</span><span class="p">,</span> <span class="n">X_target_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shadow Model Training set size:&quot;</span><span class="p">,</span> <span class="n">X_shadow_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Training set size: 36168
Test set size: 9043
Target Model Training set size: 21700
Shadow Model Training set size: 14468
</pre></div></div>
</div>
<section id="Models-training">
<h2>Models training<a class="headerlink" href="#Models-training" title="Link to this heading">#</a></h2>
<p>Now, we can train the target model. In this case, we will use a Random Forest classifier.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train the Target Model</span>
<span class="n">target_model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">target_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_target_pred</span> <span class="o">=</span> <span class="n">target_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Target Model Performance:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_target_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Target Model Performance:
Accuracy: 0.9027977441114674
</pre></div></div>
</div>
<p>We will do the same for the shadow model. Just remember that the shadow model will be trained with the shadow dataset.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train the Shadow Model</span>
<span class="n">shadow_model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">shadow_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_shadow_train</span><span class="p">,</span> <span class="n">y_shadow_train</span><span class="p">)</span>
<span class="n">y_shadow_pred</span> <span class="o">=</span> <span class="n">shadow_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Shadow Model Performance:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_shadow_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Shadow Model Performance:
Accuracy: 0.8974897710936636
</pre></div></div>
</div>
</section>
<section id="Privacy-risk-score-calculation">
<h2>Privacy risk score calculation<a class="headerlink" href="#Privacy-risk-score-calculation" title="Link to this heading">#</a></h2>
<p>Once we have the target and shadow models, we can calculate the privacy risk score for each sample in the dataset. With this metric, we can estimate the probability of a sample belonging to the training dataset of the target model. In this way we can identify which samples present a higher risk of privacy leakage. To read more about the privacy risk score, you can check the original <a class="reference external" href="https://arxiv.org/abs/2003.10595">paper</a>.</p>
<p>To measure the privacy risk score, we first need to calculate the probability of the training and testing samples belonging to the target and shadow models.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">shadow_train_probs</span> <span class="o">=</span> <span class="n">shadow_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_shadow_train</span><span class="p">)</span>
<span class="n">shadow_test_probs</span> <span class="o">=</span> <span class="n">shadow_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">target_train_probs</span> <span class="o">=</span> <span class="n">target_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_target_train</span><span class="p">)</span>
<span class="n">target_test_probs</span> <span class="o">=</span> <span class="n">target_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Having the probabilities of the input samples belonging to the target and shadow model, we can then calculate the probability of the input samples belonging to the training set by using the <code class="docutils literal notranslate"><span class="pre">privacy_risk_score</span></code> function. This function receives as input tuples with the probabilities of the training and testing samples for the target and shadow models.</p>
<p>We will first calculate the privacy risk score for the training dataset and then for the testing dataset.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">risk_score_train</span> <span class="o">=</span> <span class="n">privacy_risk_score</span><span class="p">((</span><span class="n">shadow_train_probs</span><span class="p">,</span> <span class="n">y_shadow_train</span><span class="p">),</span> <span class="p">(</span><span class="n">shadow_test_probs</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span> <span class="p">(</span><span class="n">target_train_probs</span><span class="p">,</span> <span class="n">y_target_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Privacy Risk Score for train: &quot;</span><span class="p">,</span> <span class="n">risk_score_train</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="n">risk_score_test</span> <span class="o">=</span> <span class="n">privacy_risk_score</span><span class="p">((</span><span class="n">shadow_train_probs</span><span class="p">,</span> <span class="n">y_shadow_train</span><span class="p">),</span> <span class="p">(</span><span class="n">shadow_test_probs</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span> <span class="p">(</span><span class="n">target_test_probs</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Privacy Risk Score for test: &quot;</span><span class="p">,</span> <span class="n">risk_score_test</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Mean Privacy Risk Score for train:  0.5572013708112826
Mean Privacy Risk Score for test:  0.4623020668629128
</pre></div></div>
</div>
<p>Now that we have calculated the privacy risk score of the training and testing set, we can then analyze the privacy risk of the target model by varing the threshold of the privacy risk score.</p>
<p>To do this we will calculate the precision and recall of the privacy risk score for different thresholds. We will use the ROC curve function to calculate the false positive rate and true positive rate for different thresholds and then, we will use the calculated values to analyze the privacy risk of the target model at different thresholds.</p>
<p>To create the ROC curve, we will use the <code class="docutils literal notranslate"><span class="pre">roc_curve</span></code> function from the <code class="docutils literal notranslate"><span class="pre">sklearn.metrics</span></code> module. This function receives as input the true labels and the predicted probabilities of the positive class. As labels, we know previously if the samples belong to the training or testing set, so we can use this information to create the labels for the ROC curve. On the other hand, the scores are the calculated privacy risk scores.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">risk_score_train</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">risk_score_test</span><span class="p">))))</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">risk_score_train</span><span class="p">,</span> <span class="n">risk_score_test</span><span class="p">))</span>

<span class="c1"># Compute ROC curve</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">drop_intermediate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Define threshold list and find meaningful thresholds</span>
<span class="n">threshold_list</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]</span>
<span class="n">max_prob</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">risk_score_train</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">risk_score_test</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="n">meaningful_thresholds</span> <span class="o">=</span> <span class="p">[</span><span class="n">threshold</span> <span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">threshold_list</span> <span class="k">if</span> <span class="n">threshold</span> <span class="o">&lt;=</span> <span class="n">max_prob</span><span class="p">]</span>

<span class="c1"># Find indices for meaningful thresholds</span>
<span class="n">indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">thresholds</span> <span class="o">&gt;=</span> <span class="n">threshold</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">meaningful_thresholds</span><span class="p">]</span>

<span class="c1"># Calculate precision and recall</span>
<span class="n">precision_list</span> <span class="o">=</span> <span class="n">tpr</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">tpr</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span> <span class="o">+</span> <span class="n">fpr</span><span class="p">[</span><span class="n">indices</span><span class="p">])</span>
<span class="n">recall_list</span> <span class="o">=</span> <span class="n">tpr</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>Finally, the previous calculations allow us to analyze the privacy risk of the target model at different thresholds. We can do this by analyzing the precision and recall of the privacy risk score to extract insights about the privacy risk of the model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">meaningful_thresholds</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Threshold: </span><span class="si">{</span><span class="n">threshold</span><span class="si">}</span><span class="s2">, Precision: </span><span class="si">{</span><span class="n">precision_list</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="si">}</span><span class="s2">, Recall: </span><span class="si">{</span><span class="n">recall_list</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Threshold: 1.0, Precision: 1.0, Recall: 0.0014285714285714286
Threshold: 0.9, Precision: 0.9192934519839431, Recall: 0.03400921658986175
Threshold: 0.8, Precision: 0.9192934519839431, Recall: 0.03400921658986175
Threshold: 0.7, Precision: 0.9192934519839431, Recall: 0.03400921658986175
Threshold: 0.6, Precision: 0.6012458562151735, Recall: 0.5895852534562211
Threshold: 0.5, Precision: 0.5775898398535104, Recall: 0.7221658986175116
Threshold: 0.4, Precision: 0.5480712814344799, Recall: 0.9387557603686636
</pre></div></div>
</div>
<p>With these results, we can say the following: - If the privacy risk score is set above of 0.7, there are ~3% of the training set members that can be inferred correctly by the adversary with a ~92% of precision. - If we decrease the privacy risk score to 0.6, there are ~58% of the training set members that can be inferred correctly by the adversary with a ~60% of precision. - Surpringly, there is a very small percentage (0.1%) of the training set members that can be inferred correctly by the
adversary with a ~100% of precision if the privacy risk score is set as 1. This is because the privacy risk score is calculated as the probability of the sample belonging to the training set, so if the privacy risk score is 1, the sample belongs to the training set with a probability of 1. - Finally, if the privacy risk score is set as 0.5, there are ~72% of the training set members that can be inferred correctly by the adversary with a ~57% of precision.</p>
<p>We can see that for this particular model, we could have serious privacy risks since the adversary can infer a considerable percentage of the training set members with a considerable precision. This is a privacy risk that should be taken into account when deploying the model.</p>
</section>
<section id="Changing-the-model-architecture">
<h2>Changing the model architecture<a class="headerlink" href="#Changing-the-model-architecture" title="Link to this heading">#</a></h2>
<p>Now that we have analyzed the privacy risk of the model with a Random Forest classifier, we can analyze the privacy risk of the model with a different architecture. In this case, we will change the target model to a Logistic Regression classifier maintaining the same shadow model. We will repeat the same steps as before to analyze the privacy risk of the model with a different architecture.</p>
<p>We will this analysis to observe the impact of the model choice on the privacy risk score.</p>
<p>Let’s train the target model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train the Target Model</span>
<span class="n">target_model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">target_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_target_pred</span> <span class="o">=</span> <span class="n">target_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Target Model Performance:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_target_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Target Model Performance:
Accuracy: 0.8906336392790003
</pre></div></div>
</div>
<p>Although the accuracy of the model decreases, this change is not significant.</p>
<p>Now, let’s analyze the privacy risk of the target model built with a Logistic Regression classifier.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">shadow_train_probs</span> <span class="o">=</span> <span class="n">shadow_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_shadow_train</span><span class="p">)</span>
<span class="n">shadow_test_probs</span> <span class="o">=</span> <span class="n">shadow_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">target_train_probs</span> <span class="o">=</span> <span class="n">target_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_target_train</span><span class="p">)</span>
<span class="n">target_test_probs</span> <span class="o">=</span> <span class="n">target_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">risk_score_train</span> <span class="o">=</span> <span class="n">privacy_risk_score</span><span class="p">((</span><span class="n">shadow_train_probs</span><span class="p">,</span> <span class="n">y_shadow_train</span><span class="p">),</span> <span class="p">(</span><span class="n">shadow_test_probs</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span> <span class="p">(</span><span class="n">target_train_probs</span><span class="p">,</span> <span class="n">y_target_train</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Privacy Risk Score for train: &quot;</span><span class="p">,</span> <span class="n">risk_score_train</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="n">risk_score_test</span> <span class="o">=</span> <span class="n">privacy_risk_score</span><span class="p">((</span><span class="n">shadow_train_probs</span><span class="p">,</span> <span class="n">y_shadow_train</span><span class="p">),</span> <span class="p">(</span><span class="n">shadow_test_probs</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span> <span class="p">(</span><span class="n">target_test_probs</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean Privacy Risk Score for test: &quot;</span><span class="p">,</span> <span class="n">risk_score_test</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">risk_score_test</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>

<span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">risk_score_train</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">risk_score_test</span><span class="p">))))</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">risk_score_train</span><span class="p">,</span> <span class="n">risk_score_test</span><span class="p">))</span>

<span class="c1"># Compute ROC curve</span>
<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">drop_intermediate</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Define threshold list and find meaningful thresholds</span>
<span class="n">threshold_list</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]</span>
<span class="n">max_prob</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">risk_score_train</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">risk_score_test</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="n">meaningful_thresholds</span> <span class="o">=</span> <span class="p">[</span><span class="n">threshold</span> <span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">threshold_list</span> <span class="k">if</span> <span class="n">threshold</span> <span class="o">&lt;=</span> <span class="n">max_prob</span><span class="p">]</span>

<span class="c1"># Find indices for meaningful thresholds</span>
<span class="n">indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argwhere</span><span class="p">(</span><span class="n">thresholds</span> <span class="o">&gt;=</span> <span class="n">threshold</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="n">meaningful_thresholds</span><span class="p">]</span>

<span class="c1"># Calculate precision and recall</span>
<span class="n">precision_list</span> <span class="o">=</span> <span class="n">tpr</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">tpr</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span> <span class="o">+</span> <span class="n">fpr</span><span class="p">[</span><span class="n">indices</span><span class="p">])</span>
<span class="n">recall_list</span> <span class="o">=</span> <span class="n">tpr</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">threshold</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">meaningful_thresholds</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Threshold: </span><span class="si">{</span><span class="n">threshold</span><span class="si">}</span><span class="s2">, Precision: </span><span class="si">{</span><span class="n">precision_list</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="si">}</span><span class="s2">, Recall: </span><span class="si">{</span><span class="n">recall_list</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Mean Privacy Risk Score for train:  0.39248846087198713
Mean Privacy Risk Score for test:  0.390332725228539 0.1548584345529434
Threshold: 1.0, Precision: 0.5151883448597119, Recall: 0.002350230414746544
Threshold: 0.9, Precision: 0.5036339840160396, Recall: 0.007741935483870968
Threshold: 0.8, Precision: 0.5036339840160396, Recall: 0.007741935483870968
Threshold: 0.7, Precision: 0.5036339840160396, Recall: 0.007741935483870968
Threshold: 0.6, Precision: 0.5124566467179488, Recall: 0.02870967741935484
Threshold: 0.5, Precision: 0.4995475163227362, Recall: 0.12230414746543779
Threshold: 0.4, Precision: 0.5014759264484899, Recall: 0.7450691244239631
</pre></div></div>
</div>
<p>From these new results, we can observe and extract the following insights: - First, we could observe that although the target model has changed, the accuracy of the model is still high. But the real change is in the privacy risk score. For this case, we have a mean privacy risk score of 0.4, while for the Random Forest classifier, the mean privacy risk score was 0.55. - Next, we can see that the privacy risk score is lower for the Logistic Regression classifier than for the Random Forest
classifier. This means that the adversary can infer fewer training set members with a lower precision for the Logistic Regression classifier than for the Random Forest classifier. - Finally, we can observe the same behavior for different thresholds. With an almost 2% of the training set members that can be inferred correctly by the adversary with a ~51% of precision for a privacy risk score of 0.6, while for the Random Forest classifier, this percentage was 58% with a ~60% of precision.</p>
<p>From these results, we can see that the model choice has an impact on the privacy risk score. In this case, the Logistic Regression classifier has a lower privacy risk score than the Random Forest classifier. This is an important insight to consider when deploying a model, as the privacy risk score can vary depending on the model architecture.</p>
<p>In addition, although the privacy risk score can be a useful metric to analyze the privacy risks of a model, it is important to consider other metrics and techniques to ensure the privacy of the data and the model. For example, the implementation of defenses against membership inference attacks, such as differential privacy or adversarial training, can help to mitigate the privacy risks of a model.</p>
<section id="Summary">
<h3>Summary<a class="headerlink" href="#Summary" title="Link to this heading">#</a></h3>
<p>In this notebook, we have analyzed the privacy risk of a classification model using the shadow training technique. We have calculated the privacy risk score for the training and testing datasets and then we have analyzed the privacy risk of the model at different thresholds. We have seen that the model presents a considerable privacy risk, since the adversary can infer a considerable percentage of the training set members with a considerable precision if we choose the target model as a Random
Forest classifier. We have also observed that the model choice has an impact on the privacy risk score, as the Logistic Regression classifier has a lower privacy risk score than the Random Forest classifier.</p>
<p>This analysis can help to understand the privacy risks of a model and to take actions to mitigate these risks, such as implementing defenses against membership inference attacks.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</section>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2024, Holistic AI.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.4.7.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.0.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>