

<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Explainability &#8212; holistic  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom_style.css?v=ac75cb35" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'getting_started/explainability/index';</script>
    <link rel="icon" href="../../_static/holistic_ai.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Metrics" href="metrics.html" />
    <link rel="prev" title="Fair Regression via Plug-In Estimator and Recalibration" href="../bias/mitigation/postprocessing/r_plugin_estimator_and_calibrator_plug_in_estimator_and_recalibration.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/hai_logo.svg" class="logo__image only-light" alt="holistic  documentation - Home"/>
    <img src="https://assets-global.website-files.com/6305e5d42c283515c3e71b8c/63d771efd50a073bd66193f0_Holistic-AI-Logo-Horizontal-Dark.svg" class="logo__image only-dark pst-js-only" alt="holistic  documentation - Home"/>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    Getting Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../reference/index.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../gallery/index.html">
    Example Gallery
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contributor/index.html">
    Contributor Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../changelog/index.html">
    Changelog
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://twitter.com/holistic_ai" title="Twitter" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Twitter</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/holistic-ai/holisticai" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://join.slack.com/t/holisticaicommunity/shared_invite/zt-2jamouyrn-BrMfeoBZIHT8HbLzB3P9QQ" title="Community" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-slack fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Community</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    Getting Started
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../reference/index.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../gallery/index.html">
    Example Gallery
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contributor/index.html">
    Contributor Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../changelog/index.html">
    Changelog
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://twitter.com/holistic_ai" title="Twitter" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Twitter</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/holistic-ai/holisticai" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://join.slack.com/t/holisticaicommunity/shared_invite/zt-2jamouyrn-BrMfeoBZIHT8HbLzB3P9QQ" title="Community" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-slack fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Community</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../sdk.html">Holistic AI SDK</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../sdk/qassessment.html">Setting Up a Quantitative Assessment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sdk/github_cicd.html">Setting Up a GitHub CI/CD Pipeline</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets.html">Datasets</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../technical_risks.html">Learn About AI Technical Risks</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../bias/index.html">Bias</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../bias/metrics.html">Metrics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../bias/metrics/binary_classification.html">Binary Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../bias/metrics/multi_classification.html">Multi-Class Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../bias/metrics/regression.html">Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="../bias/metrics/recommender.html">Recommender Systems</a></li>
<li class="toctree-l4"><a class="reference internal" href="../bias/metrics/clustering.html">Clustering</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../bias/mitigation.html">Mitigation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../bias/mitigation/preprocessing.html">Pre-processing Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../bias/mitigation/inprocessing.html">In-processing Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../bias/mitigation/postprocessing.html">Post-processing Methods</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 current active has-children"><a class="current reference internal" href="#">Explainability</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="metrics.html">Metrics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="metrics/spread.html">Spread Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="metrics/similarity.html">Order Cohesion Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="metrics/permutation.html">Feature Permutation-Based Metric</a></li>
<li class="toctree-l4"><a class="reference internal" href="metrics/stability.html">Stability Metrics</a></li>
<li class="toctree-l4"><a class="reference internal" href="metrics/tree.html">Tree Based Metrics</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../security/index.html">Security</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../security/metrics.html">Security Metrics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../security/metrics/shapr.html">SHAPr: SHapley vAlue-based Privacy Risk</a></li>
<li class="toctree-l4"><a class="reference internal" href="../security/metrics/attribute_attack.html">Attribute Inference Attack</a></li>
<li class="toctree-l4"><a class="reference internal" href="../security/metrics/data_minimization.html">Data Minimization</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../security/mitigation.html">Mitigation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../security/mitigation/anonymize.html">Anonymization Mitigator</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../robustness/index.html">Robustness</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../robustness/attackers/hopskipjump.html">HopSkipJumpAttack</a></li>
<li class="toctree-l3"><a class="reference internal" href="../robustness/attackers/zoo.html">ZOO: Zeroth Order Optimization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../robustness/attackers/linreggdpoisoner.html">Gradient-Based Poisoning Attackers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../robustness/metrics/index.html">Metrics</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">Getting Started</a></li>
    
    
    <li class="breadcrumb-item"><a href="../technical_risks.html" class="nav-link">Learn About AI Technical Risks</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Explainability</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="explainability">
<h1>Explainability<a class="headerlink" href="#explainability" title="Link to this heading">#</a></h1>
<p>Despite the remarkable recent evolution in prediction performance by artificial intelligence (AI) models, they are often deemed as “black boxes”, i.e., models whose prediction mechanisms cannot be understood simply from their parameters. Explainability in machine learning refers to the ability to understand and articulate how models arrive at their predictions. This is crucial for promoting transparency, trust, and accountability in AI systems. It helps in verifying model behavior, refining models, debugging unexpected behavior, and communicating model decisions to stakeholders.</p>
<nav class="contents local" id="table-of-contents">
<p class="topic-title">Table of Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#feature-importance" id="id1">Feature Importance</a></p></li>
<li><p><a class="reference internal" href="#measuring-and-mitigation" id="id2">Measuring and Mitigation</a></p></li>
</ul>
</nav>
<section id="feature-importance">
<h2><a class="toc-backref" href="#id1" role="doc-backlink">Feature Importance</a><a class="headerlink" href="#feature-importance" title="Link to this heading">#</a></h2>
<p>Feature importance is a key approach to analyzing explainability. It assesses the contribution of each feature to the model’s predictions. There are two main types of feature importance: global and local.</p>
<section id="global-feature-importance">
<h3>Global Feature Importance<a class="headerlink" href="#global-feature-importance" title="Link to this heading">#</a></h3>
<p>Global feature importance provides insights into the overall model by indicating how much each feature contributes to the model’s predictions across the entire dataset. Two common methods for global feature importance are permutation and surrogate models.</p>
<ul>
<li><p><strong>Permutation Feature Importance</strong>: This method involves shuffling the values of each feature and measuring the change in the model’s error. If shuffling a feature’s values increases the error significantly, the feature is considered important. This approach is model-agnostic and intuitive.</p>
<blockquote>
<div><p>The permutation feature importance measures the importance of a feature by calculating the increase in the model’s prediction error after the feature’s values have been perturbed. In this context, the perturbation involves shuffling the feature’s values.</p>
<p>With this approach, a feature is considered <strong>more important</strong> if shuffling its values leads to a significant increase in the model’s prediction error. Conversely, a feature is considered <strong>less important</strong> if shuffling its values results in little to no change in the model’s prediction error.</p>
<p>The basic algorithm for permutation feature importance is:</p>
<blockquote>
<div><p>Input: trained model <span class="math notranslate nohighlight">\(\hat{f}\)</span>, feature matrix <span class="math notranslate nohighlight">\(X\)</span>, target <span class="math notranslate nohighlight">\(y\)</span>, error measure <span class="math notranslate nohighlight">\(\mathcal{L}(y, \hat{f})\)</span></p>
<ol class="arabic simple">
<li><p>Estimate model error <span class="math notranslate nohighlight">\(\epsilon_{0}=\mathcal{L}(y, \hat{f}(X))\)</span></p></li>
<li><p>For each feature <span class="math notranslate nohighlight">\(j\)</span> in <span class="math notranslate nohighlight">\(1, \dots, p\)</span>:
- generate a permuted feature matrix <span class="math notranslate nohighlight">\(\bar{X}\)</span>
- estimate <span class="math notranslate nohighlight">\(\bar{\epsilon}=\mathcal{L}(y, \bar{X})\)</span>
- compute the permutation feature importance  ratio <span class="math notranslate nohighlight">\(\mathcal{F}_{j}=\frac{\bar{\epsilon}}{\epsilon_{0}}\)</span> or the difference <span class="math notranslate nohighlight">\(\mathcal{F}_{j}=\bar{\epsilon}-\epsilon_{0}\)</span></p></li>
<li><p>Sort the features by descending <span class="math notranslate nohighlight">\(\mathcal{F}\)</span></p></li>
</ol>
</div></blockquote>
<p>This algorithm follow the implementation proposed by <a class="reference external" href="https://arxiv.org/abs/1801.01489">Fisher et al. (2018)</a>.</p>
</div></blockquote>
</li>
<li><p><strong>Surrogate Models</strong>: Surrogate models involve approximating the complex model with a simpler, interpretable model (like a decision tree). By fitting the surrogate model to the predictions of the complex model, we can gain insights into the decision-making process of the original model.</p>
<blockquote>
<div><p>A surrogate model is an interpretable model designed to approximate the predictions of a more complex machine learning model. The goal is to achieve a model that balances good accuracy with interpretability. To obtain a surrogate model we can employ the following steps:</p>
<blockquote>
<div><p>Input: dataset <span class="math notranslate nohighlight">\(X\)</span>, a black-box model <span class="math notranslate nohighlight">\(g\)</span>, a interpretable model <span class="math notranslate nohighlight">\(f\)</span></p>
<ol class="arabic simple">
<li><p>Select a dataset <span class="math notranslate nohighlight">\(X\)</span></p></li>
<li><p>Get the predictions of <span class="math notranslate nohighlight">\(g\)</span></p></li>
<li><p>Train <span class="math notranslate nohighlight">\(f\)</span> on <span class="math notranslate nohighlight">\(X\)</span> and get its predictions</p></li>
<li><p>Measure the performance of <span class="math notranslate nohighlight">\(f\)</span> to replicate the predictions of <span class="math notranslate nohighlight">\(g\)</span> (e.g. R-squared)</p></li>
<li><p>Interpret the results of surrogate model</p></li>
</ol>
</div></blockquote>
</div></blockquote>
</li>
</ul>
</section>
<section id="local-feature-importance">
<h3>Local Feature Importance<a class="headerlink" href="#local-feature-importance" title="Link to this heading">#</a></h3>
<p>Local feature importance focuses on understanding the contribution of features to individual predictions. Two popular methods for local feature importance are SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic Explanations).</p>
<ul>
<li><p><strong>SHAP</strong>: provide a unified measure of feature importance for individual predictions by computing the contribution of each feature to the prediction. This method is based on cooperative game theory and ensures fair attribution of feature importance.</p>
<blockquote>
<div><p>The <a class="reference external" href="https://papers.nips.cc/paper_files/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html">SHAP</a> presents a unified framework for interpreting model’s predictions. SHAP assign each feature an importance value for a particular prediction. The work also show that game theory results guaranteeing a unique solution apply to additive feature attribution methods and SHAP is a solution with some desired proprieties: (1) local accuracy, (2) missingness, and (3) consistency.</p>
<p>Additive feature attribution have an explanation model <span class="math notranslate nohighlight">\(g\)</span> that is linear function of binary variables</p>
<div class="math notranslate nohighlight">
\[g(z') = \phi_{0} + \sum\limits_{i=1}^{M}\phi_{i}z'_{i}\]</div>
<p>where <span class="math notranslate nohighlight">\(z'\in \{0,1\}^{M}\)</span>, <span class="math notranslate nohighlight">\(M\)</span> is the number of simplified input features, and <span class="math notranslate nohighlight">\(\phi_{i}\in\mathbb{R}\)</span>.</p>
<p>Methods with the previous equation attribute an effect <span class="math notranslate nohighlight">\(\phi_{i}\)</span> to each feature, and
summing the effects of all feature attributions approximates the output <span class="math notranslate nohighlight">\(f(x)\)</span> of the original model. There are several methods that match this definition, like SHAP and LIME. But the paper argues that SHAP is the unique model that follows the equation and satisfies the desired proprieties 1, 2 and 3.</p>
<p>To achieved this, SHAP uses Shapley values, a result observed in cooperative game theory. We can define Shapley values as</p>
<div class="math notranslate nohighlight">
\[\phi_{i}(f, x) = \sum_{z'\subseteq x'} \frac{|z'|!(M-|z'|-1)!}{M!}[f_{x}(z')-f_{x}(z'_{i})]\]</div>
<p>where <span class="math notranslate nohighlight">\(|z'|\)</span> is non-zero entries in <span class="math notranslate nohighlight">\(z'\)</span>, and <span class="math notranslate nohighlight">\(z'\subseteq x'\)</span> represents all <span class="math notranslate nohighlight">\(z'\)</span> vectors where the non-zero entries are subset of non-zero entries in <span class="math notranslate nohighlight">\(x'\)</span>.</p>
</div></blockquote>
</li>
<li><p><strong>LIME</strong>: explains individual predictions by approximating the complex model with an interpretable model locally around the prediction. By perturbing the input data and observing the changes in predictions, LIME identifies the most influential features for that specific instance.</p>
<blockquote>
<div><p>The main goal of <a class="reference external" href="https://arxiv.org/pdf/1602.04938">LIME</a> is propose an explanation method to be applied in any classifier or regression model. In this context, explain is presenting visual or texts artifacts that provides qualitative understanding of the relationship between the instances components and the model’s predictions.</p>
<p>We can define the explanations produced by LIME as</p>
<div class="math notranslate nohighlight">
\[\mathcal{E}(x) = arg\min\limits_{g\in G} ~\mathcal{L}(f, g, \pi_{x})+\Omega (g)\]</div>
<p>So, the explanation <span class="math notranslate nohighlight">\(\mathcal{E}\)</span> of a given instance $x$ is equal the minimization of the fidelity function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> while having the complexity <span class="math notranslate nohighlight">\(\Omega (g)\)</span> low enough to be interpretable by humans. In this way, <span class="math notranslate nohighlight">\(\mathcal{L}(f,g, \pi_{x})\)</span> measure how unfaithful the model $g$ is in approximating the model <span class="math notranslate nohighlight">\(f\)</span> being explained in the locality defined by <span class="math notranslate nohighlight">\(\pi_{x}\)</span>.</p>
<p>The results find in the paper indicate that LIME is useful to increase trust in black-box models and model selection (avoiding models with good accuracy but with wrong motivations, i.e, using <em>a priori</em> “non-sense” features to make predictions).</p>
</div></blockquote>
</li>
</ul>
</section>
</section>
<hr class="docutils" />
<section id="measuring-and-mitigation">
<h2><a class="toc-backref" href="#id2" role="doc-backlink">Measuring and Mitigation</a><a class="headerlink" href="#measuring-and-mitigation" title="Link to this heading">#</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">Metrics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="metrics/spread.html">Spread Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="metrics/similarity.html">Order Cohesion Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="metrics/permutation.html">Feature Permutation-Based Metric</a></li>
<li class="toctree-l2"><a class="reference internal" href="metrics/stability.html">Stability Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="metrics/tree.html">Tree Based Metrics</a></li>
</ul>
</li>
</ul>
</div>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../bias/mitigation/postprocessing/r_plugin_estimator_and_calibrator_plug_in_estimator_and_recalibration.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Fair Regression via Plug-In Estimator and Recalibration</p>
      </div>
    </a>
    <a class="right-next"
       href="metrics.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Metrics</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2024, Holistic AI.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.4.7.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.0.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>